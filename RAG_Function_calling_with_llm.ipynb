{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "30Yq8V3GxTL7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG: Function Calling\n",
        "\n",
        "OpenAI provides an inbuilt mechanism to achieve function calling.\n",
        "We will try to replicate the same with some local models so that\n",
        "you can try function calling without openAI."
      ],
      "metadata": {
        "id": "Cy8ok3-3clfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "RpLU3U4r5y9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet beautifulsoup4 langchain langchain_community langchain_core langchain_groq langchain_text_splitters sentence_transformers"
      ],
      "metadata": {
        "id": "ExWKZWfsePRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7774b4b3-a20d-48b1-d97b-16fceef9e1fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m735.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "Cfq-NOWCdGTl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the google colab to create this pipeline. so its recommended to use colab secrets to store the credentials.\n",
        "\n",
        "we would be required to create account at\n",
        "\n",
        "```Pinecone\n",
        "Groq\n",
        "Langsmith\n",
        "openai\n",
        "```\n",
        "you have to copy the api keys of all the above account to the secrets. the api keys can be fetched using\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "from google.colab import userdata\n",
        "secret = userdata.get('secret-key')\n",
        "make sure to have api keys ready.\n",
        "```"
      ],
      "metadata": {
        "id": "am-egBLudHNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_key = userdata.get('groq-key')\n",
        "smith_key = userdata.get('smith-key')\n",
        "pine_key = userdata.get('pine-key')\n",
        "openai_key = userdata.get('openai-key')\n",
        "\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'rag-function-calling'\n",
        "os.environ['LANGCHAIN_API_KEY'] = smith_key\n",
        "os.environ['GROQ_API_KEY'] = groq_key"
      ],
      "metadata": {
        "id": "7JoqeyP0cvwI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBTqVcFbFavm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use case - Flight booking based on the prompt given by user.\n",
        "\n",
        "Objective is that\n",
        " - the application should understand the user query, and\n",
        " - should direct the required information to the booking function (a dummy function that is intended to do the booking).\n"
      ],
      "metadata": {
        "id": "KIpUK5Hzxu1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Calling using langchain.agents"
      ],
      "metadata": {
        "id": "30Yq8V3GxTL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets set the prompt which will make the system understand what it is supposed to do."
      ],
      "metadata": {
        "id": "1YAbbPa-xmF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"The user wants to book a flight. Extract the source, destination and date from the query. \\n\n",
        "              you first, Format the response as 'source: [source], destination: [destination], date: [date]'.\\n\n",
        "              once you get the source and destination, replace them with airport standard code, dont explain the changes in your response. \\n\n",
        "              Query: {query}\n",
        "            \"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "j-5PjzzfCP00"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse the destination and date from the structured response\n",
        "def parse_flight_details(output):\n",
        "    match_group = re.search(r\"source: ([A-Za-z\\s]+), destination: ([A-Za-z\\s]+), date: ([A-Za-z0-9\\s]+)\", output)\n",
        "\n",
        "    if match_group:\n",
        "        source = match_group.group(1)\n",
        "        destination = match_group.group(2)\n",
        "        date = match_group.group(3)\n",
        "        return f\"Flight booked from {source} to {destination} on {date}.\"\n",
        "    else:\n",
        "        return \"Could not extract complete details from the response.\""
      ],
      "metadata": {
        "id": "7Zi3MsoDA8Zk"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that calls the language model and uses the structured prompt\n",
        "def book_flight(query: str):\n",
        "    llm = ChatGroq(temperature=0)  # You can replace it another LLM\n",
        "\n",
        "    generate_queries_chain = (\n",
        "      prompt_template\n",
        "      | llm\n",
        "      | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    # Call the model with the prompt and get the output\n",
        "    output = generate_queries_chain.invoke(query)\n",
        "\n",
        "    print(f\"output after prompt generation: {output}\")\n",
        "    # Parse the structured output to extract destination and date\n",
        "    return parse_flight_details(output)"
      ],
      "metadata": {
        "id": "yg93OxF60pQs"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tool that wraps the function with structured output\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"book_flight\",\n",
        "        func=book_flight,  # Pass the full query to the function\n",
        "        description=\"Book a flight by providing Source, destination and date in the format: 'from [Source] to [destination] on [date]'.\"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "pjxrz496-w1t"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an agent with a language model\n",
        "llm = ChatGroq(temperature=0)  # You can use other models like HuggingFace here\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "MO7dLxlX-y0I"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a user query to invoke the agent\n",
        "user_query = \"Book a flight from Delhi to New York on October 20.\"\n",
        "\n",
        "# Call the agent with the query\n",
        "result = agent.run(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mlNGB-j_Crg",
        "outputId": "b4091e53-7d95-438a-cba8-669b86b5e11a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output after prompt generation: source: Delhi, destination: New York, date: October 20\n",
            "source: DEL, destination: JFK, date: October 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the result\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IdAgsF1_HPK",
        "outputId": "104c4ac6-d2d9-4095-d763-1593b1171a89"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your flight from Delhi to New York on October 20 has been booked.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function calling using Structured LLMs"
      ],
      "metadata": {
        "id": "-Ts7TeeqHppS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "FaQfPXKFy8gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BookMyFlight(BaseModel):\n",
        "    \"\"\"Book your flight using the chat assistance.\"\"\"\n",
        "\n",
        "    query: str = Field(\n",
        "        ...,\n",
        "        description=\"Book a flight by providing Source, destination and date in the format: 'from [Source] to [destination] on [date]'.\",\n",
        "    )\n",
        "    source: str = Field(\n",
        "        ...\n",
        "        , description=\"Source location\"\n",
        "    )\n",
        "    destination: str = Field(\n",
        "        ...\n",
        "        , description=\"destination location\"\n",
        "    )\n",
        "    date: Optional[str] = Field(\n",
        "        ...\n",
        "        , description=\"date of travel\"\n",
        "    )"
      ],
      "metadata": {
        "id": "DlvefnJxFQfC"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"\"\"\n",
        "  The user wants to book a flight. Extract the source, destination and date from the query. \\n\n",
        "  you first, Format the response as 'source: [source], destination: [destination], date: [date]'.\\n\n",
        "  once you get the source and destination, replace them with airport standard code, dont explain the changes in your response. \\n\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GuUxMdkkJAvD"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(temperature=0)\n",
        "\n",
        "structured_llm = llm.with_structured_output(BookMyFlight)\n",
        "\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "query_analyzer = {\"question\": RunnablePassthrough()} | prompt_template | structured_llm\n",
        "\n"
      ],
      "metadata": {
        "id": "wG3Fdxi4IfAI"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def book_flights(output: BookMyFlight):\n",
        "    return f\"Flight booked from {output.source} to {output.destination} on {output.date}.\"\n"
      ],
      "metadata": {
        "id": "_8gqPl3_Jnps"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the model with the prompt and get the output\n",
        "query = \"Book a flight from Delhi to New York on October 20.\"\n",
        "output = query_analyzer.invoke(query)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzJREEupJhK2",
        "outputId": "fd5e4248-e515-4057-8fc3-d574234df878"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BookMyFlight(query='Book a flight from Delhi to New York on October 20', source='Delhi', destination='New York', date='October 20')"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_flights(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UxGA3kgvKBrS",
        "outputId": "dd350026-7f18-492d-da83-cf16a7a94de8"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Flight booked from Delhi to New York on October 20.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bQmCbPZsKDNG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}